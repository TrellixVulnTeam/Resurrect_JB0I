{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "realTwitterWebScraper.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayaanzhaque/Resurrect/blob/master/celebrityModel/realTwitterWebScraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMj0sS2nNODy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b748f50b-16c9-4068-b974-f2632b249537"
      },
      "source": [
        "!pip install GetOldTweets3"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: GetOldTweets3 in /usr/local/lib/python3.6/dist-packages (0.0.11)\n",
            "Requirement already satisfied: pyquery>=1.2.10 in /usr/local/lib/python3.6/dist-packages (from GetOldTweets3) (1.4.1)\n",
            "Requirement already satisfied: lxml>=3.5.0 in /usr/local/lib/python3.6/dist-packages (from GetOldTweets3) (4.2.6)\n",
            "Requirement already satisfied: cssselect>0.7.9 in /usr/local/lib/python3.6/dist-packages (from pyquery>=1.2.10->GetOldTweets3) (1.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbAcXheFNWMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing GetOldTweets3\n",
        "import GetOldTweets3 as got\n",
        "# Importing pandas\n",
        "import pandas as pd\n",
        "\n",
        "def get_tweets(username, top_only, start_date, end_date, max_tweets):\n",
        "   \n",
        "    # specifying tweet search criteria \n",
        "    tweetCriteria = got.manager.TweetCriteria().setUsername(username)\\\n",
        "                          .setTopTweets(top_only)\\\n",
        "                          .setSince(start_date)\\\n",
        "                          .setUntil(end_date)\\\n",
        "                          .setMaxTweets(max_tweets)\n",
        "    \n",
        "    # scraping tweets based on criteria\n",
        "    tweet = got.manager.TweetManager.getTweets(tweetCriteria)\n",
        "    \n",
        "    # creating list of tweets with the tweet attributes \n",
        "    # specified in the list comprehension\n",
        "    text_tweets = [[\n",
        "                    tw.date,\n",
        "                    tw.username,\n",
        "                tw.text] for tw in tweet]\n",
        "    \n",
        "    # creating dataframe, assigning column names to list of\n",
        "    # tweets corresponding to tweet attributes\n",
        "    news_df = pd.DataFrame(text_tweets, \n",
        "                            columns = ['date', 'sender_name', 'text'])\n",
        "    \n",
        "    return news_df\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRUXBq5DIX3_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "usernames = [\"kobebryant\"]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqzYbyICI5Ps",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "eb5a6d41-c2b3-4404-ab66-a0ea2677abc0"
      },
      "source": [
        "for username in usernames:\n",
        "  givenUsername = username\n",
        "  trainTweetCount = 500\n",
        "\n",
        "  tweet_df = get_tweets(givenUsername, \n",
        "                      top_only = True,\n",
        "                      start_date = \"2015-01-01\", \n",
        "                      end_date = \"2019-11-01\",\n",
        "                      max_tweets = trainTweetCount).sort_values('date', ascending=False)\n",
        "\n",
        "  tweet_df.to_csv(\"/content/\" + givenUsername + \".csv\")\n",
        "  print(tweet_df)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                         date  ...                                               text\n",
            "19  2019-10-23 18:04:50+00:00  ...  one of you that follows and purchases will get...\n",
            "0   2019-10-23 18:04:33+00:00  ...  Launching my new LIVE channel on TalkShopLive!...\n",
            "1   2019-10-11 04:16:52+00:00  ...  Congrats @WashMystics and @De11eDonne on winni...\n",
            "2   2019-09-25 23:04:18+00:00  ...  Itâ€™s the magic within each of us that gives us...\n",
            "20  2019-09-23 15:02:04+00:00  ...                     Happy Birthday @PHEEsespieces \n",
            "..                        ...  ...                                                ...\n",
            "314 2015-01-29 07:09:33+00:00  ...  Surgery went well! Thank u for your well wishe...\n",
            "315 2015-01-25 23:55:04+00:00  ...  Congrats Coach K! Amazing accomplishment #1Kfo...\n",
            "316 2015-01-23 17:48:38+00:00  ...  This is what happens when I pass too much! #Sh...\n",
            "317 2015-01-06 02:55:38+00:00  ...  @kobebryant: My prayers are with the Kupchak f...\n",
            "318 2015-01-04 16:52:56+00:00  ...  #StuartScottSayings changed the game #BOOYAH #...\n",
            "\n",
            "[319 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}